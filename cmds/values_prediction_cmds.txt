python persona_understanding/value_measurement/values_prediction.py --openai-api-key token-abc123 \
                                                            --model-base-url http://localhost:8000/v1 \
                                                            --user-profile-dataset datasets/recruitment_data.csv \
                                                            --starting-row 0 \
                                                            --ending-row 200 \
                                                            --dialogue-file datasets/generated_dialogues/first_200_rows.jsonl \
                                                            --evaluated_model nvidia/Llama-3.1-Nemotron-70B-Instruct-HF \
                                                            --direct_output_file_path values_results/Llama-3.1-Nemotron-70B-Instruct-HF/vsm/direct_questions/first_200.jsonl \
                                                            --dialogue_output_file_path values_results/Llama-3.1-Nemotron-70B-Instruct-HF/vsm/dialogue_questions/first_200.jsonl \
                                                            --verbose 1 \
                                                            --storage-step 10 2>&1 | tee logs/values_prediction_vsm_first_200.txt



python persona_understanding/value_measurement/values_prediction.py --openai-api-key sk-f794be8cb48e43f99e3cd04a20dd76aa \
                --model-base-url https://api.deepseek.com \
                --user-profile-dataset datasets/recruitment_data.csv \
                --starting-row 0 \
                --ending-row 200 \
                --dialogue-file datasets/generated_dialogues/first_200_rows.jsonl \
                --evaluated_model deepseek-chat \
                --direct_output_file_path values_results/deepseek-v3/vsm/direct_questions/first_200.jsonl \
                --dialogue_output_file_path values_results/deepseek-v3/vsm/dialogue_questions/first_200.jsonl \
                --verbose 1 \
                --llm_server llm_platform \
                --storage-step 10 2>&1 | tee logs/deepseek_values_prediction_vsm_first_200.txt

python persona_understanding/value_measurement/values_prediction.py --openai-api-key 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 \
                --model-base-url https://openrouter.ai/api/v1 \
                --user-profile-dataset datasets/recruitment_data.csv \
                --starting-row 0 \
                --ending-row 2 \
                --dialogue-file datasets/generated_dialogues/first_1000_rows.jsonl \
                --evaluated_model qwen/qwen-2.5-72b-instruct \
                --direct_output_file_path values_results/qwen2.5-72B/vsm/direct_questions/first_2.jsonl \
                --dialogue_output_file_path values_results/qwen2.5-72B/vsm/dialogue_questions/first_2.jsonl \
                --verbose 1 \
                --llm_server llm_platform \
                --storage-step 10 2>&1 | tee logs/qwen2.5-72b_values_prediction_vsm_first_2.txt

## Start vllm
vllm serve meta-llama/Llama-3.1-70B-Instruct \
                --max-model-len 16384 \
                --max-num-seqs 64 \
                --max-num-batched-tokens 48000 \
                --api-key token-123 --port 5000 \
                --tensor-parallel 4 \
                --chat-template ./templates/tool_chat_llama3.1.jinja \
                --chat-template-content-format auto \
                --enable-auto-tool-choice --tool-call-parser llama3_json \

vllm serve Qwen/Qwen2.5-7B-Instruct-1M \
                --max-model-len 16384 \
                --max-num-seqs 64 \
                --max-num-batched-tokens 48000 \
                --api-key token-123 --port 5000 \
                --enable-auto-tool-choice --tool-call-parser hermes \
                --tensor-parallel 4 \
                --chat-template ./templates/tool_chat_llama3.1.jinja \
                --chat-template-content-format auto \
                
vllm serve Qwen/Qwen2.5-72B-Instruct \
                --max-model-len 32768 \
                --max-num-seqs 64 \
                --max-num-batched-tokens 65536 \
                --api-key token-123 --port 5000 \
                --enable-auto-tool-choice --tool-call-parser hermes \
                --tensor-parallel 4 \
                --disable-custom-all-reduce

vllm serve Qwen/QwQ-32B \
                --max-model-len 32768 \
                --max-num-seqs 8 \
                --max-num-batched-tokens 48000 \
                --api-key token-123 --port 8000 \
                --enable-reasoning --reasoning-parser deepseek_r1 \
                --tensor-parallel 4 \
                --disable-custom-all-reduce

python persona_understanding/value_measurement/values_prediction.py --openai-api-key token-123 \
                --model-base-url http://localhost:5000/v1 \
                --user-profile-dataset datasets/recruitment_data.csv \
                --starting-row 0 \
                --ending-row 20 \
                --dialogue-file datasets/generated_dialogues/first_1000_rows.jsonl \
                --evaluated_model meta-llama/Llama-3.1-8B-Instruct \
                --direct_output_file_path values_results/llama3.1-8b/vsm/direct_questions/first_20.jsonl \
                --dialogue_output_file_path values_results/llama3.1-8b/vsm/dialogue_questions/first_20.jsonl \
                --verbose 1 \
                --llm_server vllm \
                --storage-step 10 2>&1 | tee logs/llama3.1_8b_20.txt

python persona_understanding/value_measurement/values_prediction.py --openai-api-key token-123 \
                --model-base-url http://localhost:5000/v1 \
                --user-profile-dataset datasets/recruitment_data.csv \
                --starting-row 0 \
                --ending-row 1000 \
                --dialogue-file datasets/generated_dialogues/first_1000_rows.jsonl \
                --evaluated_model meta-llama/Llama-3.1-70B-Instruct \
                --direct_output_file_path values_results/llama3.1-70b/vsm/direct_questions/first_20.jsonl \
                --dialogue_output_file_path values_results/llama3.1-70b/vsm/dialogue_questions/first_20.jsonl \
                --verbose 1 \
                --llm_server vllm \
                --storage-step 10 2>&1 | tee logs/llama3.1_70b.txt

python persona_understanding/value_measurement/values_prediction.py --openai-api-key token-123 \
                --model-base-url http://localhost:5000/v1 \
                --user-profile-dataset datasets/recruitment_data.csv \
                --starting-row 0 \
                --ending-row 1000 \
                --dialogue-file datasets/generated_dialogues/first_1000_rows.jsonl \
                --evaluated_model Qwen/Qwen2.5-7B-Instruct-1M \
                --direct_output_file_path values_results/qwen2.5-7b/vsm/direct_questions/first_1000.jsonl \
                --dialogue_output_file_path values_results/qwen2.5-7b/vsm/dialogue_questions/first_1000.jsonl \
                --verbose 1 \
                --llm_server vllm \
                --storage-step 10 2>&1 | tee logs/qwen2.5_7b.txt


python persona_understanding/value_measurement/values_prediction.py --openai-api-key None \
                --model-base-url http://localhost:30000/v1 \
                --user-profile-dataset datasets/recruitment_data.csv \
                --starting-row 0 \
                --ending-row 1000 \
                --dialogue-file datasets/generated_dialogues/first_1000_rows.jsonl \
                --evaluated_model Qwen/Qwen2.5-72B-Instruct \
                --direct_output_file_path values_results/Qwen2.5-72B-Instruct/vsm/direct_questions/first_1000.jsonl \
                --dialogue_output_file_path values_results/Qwen2.5-72B-Instruct/vsm/dialogue_questions/first_1000.jsonl \
                --verbose 1 \
                --llm_server sglang \
                --storage-step 10 2>&1 | tee logs/qwen2.5_72b.txt

python persona_understanding/value_measurement/values_prediction.py --openai-api-key None \
                --model-base-url http://localhost:30000/v1 \
                --user-profile-dataset datasets/recruitment_data.csv \
                --starting-row 0 \
                --ending-row 1000 \
                --dialogue-file datasets/generated_dialogues/first_1000_rows.jsonl \
                --evaluated_model Qwen/QwQ-32B \
                --direct_output_file_path values_results/QwQ-32B/vsm/direct_questions/first_1000.jsonl \
                --dialogue_output_file_path values_results/QwQ-32B/vsm/dialogue_questions/first_1000.jsonl \
                --verbose 1 \
                --llm_server sglang \
                --reasoning \
                --storage-step 10 2>&1 | tee logs/qwq-32b.txt


python persona_understanding/value_measurement/values_prediction.py --openai-api-key None \
                --model-base-url http://localhost:30000/v1 \
                --user-profile-dataset datasets/recruitment_data.csv \
                --starting-row 0 \
                --ending-row 10 \
                --dialogue-file datasets/generated_dialogues/first_1000_rows.jsonl \
                --evaluated_model Qwen/QwQ-32B \
                --direct_output_file_path values_results/QwQ-32B/vsm/direct_questions/first_10.jsonl \
                --dialogue_output_file_path values_results/QwQ-32B/vsm/dialogue_questions/first_10.jsonl \
                --verbose 1 \
                --llm_server sglang \
                --reasoning \
                --storage-step 10 2>&1 | tee logs/qwq-32b.txt

# SGLang

python -m sglang.launch_server --model-path Qwen/Qwen2.5-72B-Instruct --host 0.0.0.0 --grammar-backend xgrammar --tp-size 4
python -m sglang.launch_server --model-path Qwen/QwQ-32B --host 0.0.0.0 --grammar-backend xgrammar 

python -m sglang.launch_server --model-path Qwen/QwQ-32B --host 0.0.0.0 --grammar-backend xgrammar --reasoning-parser deepseek-r1 --tool-call-parser qwen25